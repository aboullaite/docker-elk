# Use a Beats input plugin
input {
beats {
  port => 5000
}
}
# parsing nginx logs with logstachhere

filter {
if [type] == "nginx-access" {
grok {
match => [ "message" , "%{COMBINEDAPACHELOG}+%{GREEDYDATA:extra_fields}"]
overwrite => [ "message" ]
}

mutate {
  convert => ["response", "integer"]
  convert => ["bytes", "integer"]
  convert => ["responsetime", "float"]
}

geoip {
  source => "clientip"
  target => "geoip"
  add_tag => [ "nginx-geoip" ]
}

date {
  match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
  remove_field => [ "timestamp" ]
}

useragent {
  source => "agent"
}
} else if [type] == "nginx-error"{
  grok {
    match => [ "message", "(?<timestamp>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[%{DATA:nginx_severity}\] %{NOTSPACE} %{NOTSPACE} (?<nginx_message>(.|\r|\n)*)(?:, client: (?<nginx_client_ip>%{IP}|%{HOSTNAME}))(?:, server: %{IPORHOST:nginx_server})(?:, request: %{QS:nginx_request})?(?:, host: %{QS:nginx_host})?(?:, referrer: %{URI:nginx_referrer})?"]
    overwrite => [ "message" ]
  }
  geoip {
    source => "client"
    target => "geoip"
    add_tag => [ "nginx-geoip" ]
  }

  date {
    match => [ "timestamp" , "YYYY/MM/dd HH:mm:ss" ]
    remove_field => [ "timestamp" ]
  }
  } else if [type] ==  "syslog" {
    grok {
      match => { "message" => "%{SYSLOGLINE}" }
      overwrite => [ "message" ]
    }
  }
}
# We want Elasticsearch to store our logs
output {
elasticsearch {
  hosts => ["elasticsearch:9200"]
}
}
